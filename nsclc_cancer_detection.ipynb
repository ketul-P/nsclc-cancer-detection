{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYoaEJoHDHBJ",
        "outputId": "648648c8-2167-422b-ebd5-2151a681a99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rB66-rG95_FR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models,layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lN1Lo2CfvKFU"
      },
      "outputs": [],
      "source": [
        "def getDataSize(path):\n",
        "  image_count = {}\n",
        "\n",
        "  for x in os.listdir(path):\n",
        "    image_count[x] = len(os.listdir(os.path.join(path, x)))\n",
        "\n",
        "  return image_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z8wgwFvouxZ3"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/drive/MyDrive/chest_ct_scans/train'\n",
        "test_path = '/content/drive/MyDrive/chest_ct_scans/test'\n",
        "valid_path = '/content/drive/MyDrive/chest_ct_scans/valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DjMauWCjZcWN"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "haOntBxxbshv"
      },
      "outputs": [],
      "source": [
        "def generateImage(path):\n",
        "  generate_data = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                horizontal_flip=True,\n",
        "                                fill_mode='nearest',\n",
        "                                zoom_range=0.2,\n",
        "                                shear_range=0.2,\n",
        "                                width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,\n",
        "                                rotation_range=30)\n",
        "\n",
        "  return generate_data.flow_from_directory(path, batch_size=batch_size, target_size=(256, 256), color_mode='grayscale', class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IGRyAFMI4rOE"
      },
      "outputs": [],
      "source": [
        "def generateImageRGB(path):\n",
        "  generate_data = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                horizontal_flip=True,\n",
        "                                fill_mode='nearest',\n",
        "                                zoom_range=0.2,\n",
        "                                shear_range=0.2,\n",
        "                                width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,\n",
        "                                rotation_range=30)\n",
        "\n",
        "  return generate_data.flow_from_directory(path, batch_size=batch_size, target_size=(256, 256), class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsx919OXRYvs",
        "outputId": "05d5c8f0-edc9-47f4-a4c3-cd2b78ec658a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 986 images belonging to 5 classes.\n",
            "Found 150 images belonging to 5 classes.\n",
            "Found 132 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = generateImage(train_path)\n",
        "test_data = generateImage(test_path)\n",
        "valid_data = generateImage(valid_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_classes = len(train_data.class_indices)"
      ],
      "metadata": {
        "id": "IMAXYz1H6N09"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99bJHWhi39o"
      },
      "source": [
        "## Basic Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0MLtreR_uMwz"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, GlobalAveragePooling2D\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),activation='relu',input_shape=(256,256,1)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dropout(rate=0.50))\n",
        "\n",
        "model.add(Dense(units=number_of_classes,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVnSMkoiJ1e9",
        "outputId": "36cd17c0-ae56-44ec-cc8c-42f84d1c35ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 254, 254, 32)      320       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 252, 252, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 126, 126, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 126, 126, 64)      0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1016064)           0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                65028160  \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,047,301\n",
            "Trainable params: 65,047,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF6d8aDzEtle",
        "outputId": "c5d0e143-fdbc-4ad7-ced2-e897ca625411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "8/8 [==============================] - 61s 7s/step - loss: 6.7910 - accuracy: 0.2812 - val_loss: 1.8110 - val_accuracy: 0.2812\n",
            "Epoch 2/64\n",
            "8/8 [==============================] - 53s 7s/step - loss: 1.5400 - accuracy: 0.3438 - val_loss: 1.4937 - val_accuracy: 0.2812\n",
            "Epoch 3/64\n",
            "8/8 [==============================] - 47s 6s/step - loss: 1.5750 - accuracy: 0.3750 - val_loss: 1.3159 - val_accuracy: 0.4844\n",
            "Epoch 4/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.3230 - accuracy: 0.5000 - val_loss: 1.3080 - val_accuracy: 0.4375\n",
            "Epoch 5/64\n",
            "8/8 [==============================] - 40s 5s/step - loss: 1.4055 - accuracy: 0.4688 - val_loss: 1.3505 - val_accuracy: 0.3906\n",
            "Epoch 6/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.4227 - accuracy: 0.4375 - val_loss: 1.2824 - val_accuracy: 0.4062\n",
            "Epoch 7/64\n",
            "8/8 [==============================] - 36s 5s/step - loss: 1.2833 - accuracy: 0.5781 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
            "Epoch 8/64\n",
            "8/8 [==============================] - 36s 5s/step - loss: 1.3974 - accuracy: 0.4531 - val_loss: 1.5248 - val_accuracy: 0.3750\n",
            "Epoch 9/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.2647 - accuracy: 0.4844 - val_loss: 1.3064 - val_accuracy: 0.4375\n",
            "Epoch 10/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.3541 - accuracy: 0.4688 - val_loss: 1.3036 - val_accuracy: 0.3438\n",
            "Epoch 11/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.4904 - accuracy: 0.3281 - val_loss: 1.3086 - val_accuracy: 0.3594\n",
            "Epoch 12/64\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.3158 - accuracy: 0.4310 - val_loss: 1.3021 - val_accuracy: 0.3594\n",
            "Epoch 13/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.2872 - accuracy: 0.4062 - val_loss: 1.1585 - val_accuracy: 0.4688\n",
            "Epoch 14/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.1206 - accuracy: 0.5625 - val_loss: 1.2243 - val_accuracy: 0.3906\n",
            "Epoch 15/64\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.2964 - accuracy: 0.4844 - val_loss: 1.1373 - val_accuracy: 0.4219\n",
            "Epoch 16/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.1666 - accuracy: 0.5000 - val_loss: 1.1878 - val_accuracy: 0.3750\n",
            "Epoch 17/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.3013 - accuracy: 0.4375 - val_loss: 1.2608 - val_accuracy: 0.3594\n",
            "Epoch 18/64\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.2993 - accuracy: 0.4531 - val_loss: 1.2026 - val_accuracy: 0.4219\n",
            "Epoch 19/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0210 - accuracy: 0.5938 - val_loss: 1.0688 - val_accuracy: 0.4531\n",
            "Epoch 20/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.2285 - accuracy: 0.4844 - val_loss: 1.1219 - val_accuracy: 0.4375\n",
            "Epoch 21/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.2423 - accuracy: 0.4844 - val_loss: 1.1100 - val_accuracy: 0.4844\n",
            "Epoch 22/64\n",
            "8/8 [==============================] - 51s 7s/step - loss: 1.1395 - accuracy: 0.5000 - val_loss: 1.1527 - val_accuracy: 0.4531\n",
            "Epoch 23/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.2553 - accuracy: 0.4844 - val_loss: 1.0465 - val_accuracy: 0.5312\n",
            "Epoch 24/64\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.2204 - accuracy: 0.4688 - val_loss: 1.1190 - val_accuracy: 0.5312\n",
            "Epoch 25/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.1634 - accuracy: 0.4844 - val_loss: 1.1020 - val_accuracy: 0.5312\n",
            "Epoch 26/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.0527 - accuracy: 0.5312 - val_loss: 1.0774 - val_accuracy: 0.3750\n",
            "Epoch 27/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.0425 - accuracy: 0.5625 - val_loss: 1.2589 - val_accuracy: 0.3125\n",
            "Epoch 28/64\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.9149 - accuracy: 0.6406 - val_loss: 1.0070 - val_accuracy: 0.5156\n",
            "Epoch 29/64\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.1572 - accuracy: 0.5156 - val_loss: 1.0939 - val_accuracy: 0.4375\n",
            "Epoch 30/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.2796 - accuracy: 0.4375 - val_loss: 1.0516 - val_accuracy: 0.5000\n",
            "Epoch 31/64\n",
            "8/8 [==============================] - 36s 5s/step - loss: 1.2104 - accuracy: 0.4844 - val_loss: 0.8585 - val_accuracy: 0.5938\n",
            "Epoch 32/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.2904 - accuracy: 0.4062 - val_loss: 0.9908 - val_accuracy: 0.5156\n",
            "Epoch 33/64\n",
            "8/8 [==============================] - 48s 6s/step - loss: 1.0975 - accuracy: 0.5469 - val_loss: 1.1428 - val_accuracy: 0.4375\n",
            "Epoch 34/64\n",
            "8/8 [==============================] - 40s 5s/step - loss: 1.0560 - accuracy: 0.6207 - val_loss: 1.0260 - val_accuracy: 0.5156\n",
            "Epoch 35/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.1213 - accuracy: 0.5312 - val_loss: 1.0241 - val_accuracy: 0.5625\n",
            "Epoch 36/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.2906 - accuracy: 0.4531 - val_loss: 1.1979 - val_accuracy: 0.5000\n",
            "Epoch 37/64\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.0085 - accuracy: 0.5469 - val_loss: 0.9669 - val_accuracy: 0.5469\n",
            "Epoch 38/64\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0285 - accuracy: 0.6094 - val_loss: 0.9106 - val_accuracy: 0.5781\n",
            "Epoch 39/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.2013 - accuracy: 0.5312 - val_loss: 1.0521 - val_accuracy: 0.5156\n",
            "Epoch 40/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0314 - accuracy: 0.5938 - val_loss: 1.0981 - val_accuracy: 0.4844\n",
            "Epoch 41/64\n",
            "8/8 [==============================] - 36s 5s/step - loss: 1.1206 - accuracy: 0.5938 - val_loss: 1.0179 - val_accuracy: 0.5469\n",
            "Epoch 42/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.1066 - accuracy: 0.5625 - val_loss: 1.0429 - val_accuracy: 0.5469\n",
            "Epoch 43/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0240 - accuracy: 0.6250 - val_loss: 1.0569 - val_accuracy: 0.5000\n",
            "Epoch 44/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.0723 - accuracy: 0.5781 - val_loss: 0.8208 - val_accuracy: 0.6562\n",
            "Epoch 45/64\n",
            "8/8 [==============================] - 40s 5s/step - loss: 1.1213 - accuracy: 0.5172 - val_loss: 0.8695 - val_accuracy: 0.5000\n",
            "Epoch 46/64\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.9429 - accuracy: 0.5938 - val_loss: 1.0338 - val_accuracy: 0.4844\n",
            "Epoch 47/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.9377 - accuracy: 0.5312 - val_loss: 1.0349 - val_accuracy: 0.4219\n",
            "Epoch 48/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.0211 - accuracy: 0.6250 - val_loss: 0.9061 - val_accuracy: 0.5469\n",
            "Epoch 49/64\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.9506 - accuracy: 0.6406 - val_loss: 0.9516 - val_accuracy: 0.4062\n",
            "Epoch 50/64\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.2982 - accuracy: 0.4688 - val_loss: 0.8693 - val_accuracy: 0.5625\n",
            "Epoch 51/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0532 - accuracy: 0.6250 - val_loss: 0.8889 - val_accuracy: 0.6406\n",
            "Epoch 52/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.9145 - accuracy: 0.6406 - val_loss: 1.0650 - val_accuracy: 0.4844\n",
            "Epoch 53/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0407 - accuracy: 0.5469 - val_loss: 1.0147 - val_accuracy: 0.5000\n",
            "Epoch 54/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.1166 - accuracy: 0.5312 - val_loss: 1.0458 - val_accuracy: 0.5938\n",
            "Epoch 55/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.9185 - accuracy: 0.5312 - val_loss: 0.8574 - val_accuracy: 0.5000\n",
            "Epoch 56/64\n",
            "8/8 [==============================] - 36s 5s/step - loss: 1.0376 - accuracy: 0.6406 - val_loss: 0.9473 - val_accuracy: 0.5000\n",
            "Epoch 57/64\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.9598 - accuracy: 0.6406 - val_loss: 0.9140 - val_accuracy: 0.5312\n",
            "Epoch 58/64\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0155 - accuracy: 0.5938 - val_loss: 0.8543 - val_accuracy: 0.5781\n",
            "Epoch 59/64\n",
            "8/8 [==============================] - 54s 7s/step - loss: 1.0617 - accuracy: 0.5156 - val_loss: 1.0662 - val_accuracy: 0.4844\n",
            "Epoch 60/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0917 - accuracy: 0.5625 - val_loss: 0.8715 - val_accuracy: 0.5781\n",
            "Epoch 61/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.8915 - accuracy: 0.7031 - val_loss: 0.8577 - val_accuracy: 0.6406\n",
            "Epoch 62/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.1634 - accuracy: 0.5625 - val_loss: 0.8889 - val_accuracy: 0.5312\n",
            "Epoch 63/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.9362 - accuracy: 0.5625 - val_loss: 0.9138 - val_accuracy: 0.5312\n",
            "Epoch 64/64\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0531 - accuracy: 0.5625 - val_loss: 0.9394 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ea85e6e60>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model.fit(x=train_data, steps_per_epoch=8, epochs=64, validation_data=test_data, validation_steps=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGCZwHPvi_HK"
      },
      "source": [
        "## MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scq-p5YA3eut",
        "outputId": "aa5a8fd7-283f-4ec8-cde3-b96d83569970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 986 images belonging to 5 classes.\n",
            "Found 150 images belonging to 5 classes.\n",
            "Found 132 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = generateImageRGB(train_path)\n",
        "test_data = generateImageRGB(test_path)\n",
        "valid_data = generateImageRGB(valid_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZI8xrLXjFkc",
        "outputId": "3346d93f-701a-47bc-8053-9201f10b16e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications import MobileNet\n",
        "from keras.models import Model\n",
        "\n",
        "base_model = MobileNet(input_shape=(256, 256, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False  # Freeze the pre-trained layers\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x=Dense(128,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(5,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bLrkwzS4Tt9",
        "outputId": "28559704-e78f-401f-bf52-aa8fb4f4cf19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 128, 128, 32)      864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 128, 128, 32)     128       \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 128, 128, 32)     288       \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 128, 128, 32)     128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 128, 128, 64)      2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 128, 128, 64)     256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 129, 129, 64)      0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 64, 64, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 64, 64, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 64, 64, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 64, 64, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 64, 64, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 64, 64, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 64, 64, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 64, 64, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 65, 65, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 32, 32, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 32, 32, 256)       32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 32, 32, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 32, 32, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 32, 32, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 32, 32, 256)       65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 32, 32, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 33, 33, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 16, 16, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 16, 16, 512)       131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 16, 16, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 16, 16, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 16, 16, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 16, 16, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 16, 16, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 16, 16, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 16, 16, 512)      4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 16, 16, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 16, 16, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 16, 16, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 16, 16, 512)      4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 16, 16, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 16, 16, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 16, 16, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 17, 17, 512)      0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 8, 8, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 8, 8, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 8, 8, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 8, 8, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 8, 8, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 8, 8, 1024)       9216      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 8, 8, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 8, 8, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 8, 8, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 8, 8, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 8, 8, 1024)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,869,573\n",
            "Trainable params: 1,640,709\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ747cZK0Fvl",
        "outputId": "b815fc76-308a-42ca-c885-a0c9bdd7fec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "8/8 [==============================] - 21s 2s/step - loss: 1.9092 - accuracy: 0.3281 - val_loss: 1.5119 - val_accuracy: 0.4722\n",
            "Epoch 2/64\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3520 - accuracy: 0.4688 - val_loss: 0.9180 - val_accuracy: 0.6528\n",
            "Epoch 3/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 1.0829 - accuracy: 0.5469 - val_loss: 0.9591 - val_accuracy: 0.5417\n",
            "Epoch 4/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.9227 - accuracy: 0.6379 - val_loss: 0.8936 - val_accuracy: 0.6181\n",
            "Epoch 5/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 1.0307 - accuracy: 0.5000 - val_loss: 0.9424 - val_accuracy: 0.6111\n",
            "Epoch 6/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.8185 - accuracy: 0.5938 - val_loss: 0.8122 - val_accuracy: 0.5903\n",
            "Epoch 7/64\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.8824 - accuracy: 0.5312 - val_loss: 0.8025 - val_accuracy: 0.5764\n",
            "Epoch 8/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7908 - accuracy: 0.6875 - val_loss: 0.7293 - val_accuracy: 0.5972\n",
            "Epoch 9/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7159 - accuracy: 0.6094 - val_loss: 1.0375 - val_accuracy: 0.5417\n",
            "Epoch 10/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.8980 - accuracy: 0.6094 - val_loss: 0.7299 - val_accuracy: 0.5903\n",
            "Epoch 11/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.8678 - accuracy: 0.5938 - val_loss: 0.9017 - val_accuracy: 0.6111\n",
            "Epoch 12/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 0.8533 - accuracy: 0.6094 - val_loss: 0.8465 - val_accuracy: 0.6111\n",
            "Epoch 13/64\n",
            "8/8 [==============================] - 26s 4s/step - loss: 0.7872 - accuracy: 0.5781 - val_loss: 0.7989 - val_accuracy: 0.5556\n",
            "Epoch 14/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7737 - accuracy: 0.5469 - val_loss: 0.7569 - val_accuracy: 0.6389\n",
            "Epoch 15/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.8132 - accuracy: 0.5862 - val_loss: 0.8725 - val_accuracy: 0.5486\n",
            "Epoch 16/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.8464 - accuracy: 0.5938 - val_loss: 0.7420 - val_accuracy: 0.6458\n",
            "Epoch 17/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.6853 - accuracy: 0.6406 - val_loss: 0.8035 - val_accuracy: 0.5972\n",
            "Epoch 18/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.4278 - accuracy: 0.8281 - val_loss: 0.8631 - val_accuracy: 0.5903\n",
            "Epoch 19/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.7430 - accuracy: 0.6207 - val_loss: 0.7292 - val_accuracy: 0.6389\n",
            "Epoch 20/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6288 - accuracy: 0.7031 - val_loss: 0.8978 - val_accuracy: 0.5556\n",
            "Epoch 21/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6019 - accuracy: 0.7188 - val_loss: 0.6841 - val_accuracy: 0.6458\n",
            "Epoch 22/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7527 - accuracy: 0.7031 - val_loss: 0.9850 - val_accuracy: 0.5625\n",
            "Epoch 23/64\n",
            "8/8 [==============================] - 26s 4s/step - loss: 0.7599 - accuracy: 0.6406 - val_loss: 0.7662 - val_accuracy: 0.5903\n",
            "Epoch 24/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.7497 - accuracy: 0.5781 - val_loss: 0.7436 - val_accuracy: 0.6389\n",
            "Epoch 25/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.5768 - accuracy: 0.7812 - val_loss: 0.9838 - val_accuracy: 0.5000\n",
            "Epoch 26/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6512 - accuracy: 0.7031 - val_loss: 0.7195 - val_accuracy: 0.6528\n",
            "Epoch 27/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.7079 - accuracy: 0.7031 - val_loss: 0.9073 - val_accuracy: 0.5833\n",
            "Epoch 28/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6002 - accuracy: 0.7500 - val_loss: 0.8408 - val_accuracy: 0.6250\n",
            "Epoch 29/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6596 - accuracy: 0.7188 - val_loss: 0.9270 - val_accuracy: 0.5694\n",
            "Epoch 30/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.7813 - accuracy: 0.6875 - val_loss: 0.7258 - val_accuracy: 0.5972\n",
            "Epoch 31/64\n",
            "8/8 [==============================] - 23s 3s/step - loss: 0.7501 - accuracy: 0.6250 - val_loss: 0.9775 - val_accuracy: 0.5625\n",
            "Epoch 32/64\n",
            "8/8 [==============================] - 29s 4s/step - loss: 0.8368 - accuracy: 0.6406 - val_loss: 0.8659 - val_accuracy: 0.5139\n",
            "Epoch 33/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 0.6650 - accuracy: 0.6875 - val_loss: 0.8119 - val_accuracy: 0.5556\n",
            "Epoch 34/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 0.7558 - accuracy: 0.6250 - val_loss: 0.6732 - val_accuracy: 0.6944\n",
            "Epoch 35/64\n",
            "8/8 [==============================] - 26s 4s/step - loss: 0.6932 - accuracy: 0.6875 - val_loss: 0.7884 - val_accuracy: 0.5764\n",
            "Epoch 36/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7437 - accuracy: 0.7031 - val_loss: 0.7932 - val_accuracy: 0.6528\n",
            "Epoch 37/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7411 - accuracy: 0.6406 - val_loss: 0.7044 - val_accuracy: 0.6875\n",
            "Epoch 38/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6748 - accuracy: 0.7031 - val_loss: 0.6953 - val_accuracy: 0.6250\n",
            "Epoch 39/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6977 - accuracy: 0.6719 - val_loss: 0.7803 - val_accuracy: 0.5972\n",
            "Epoch 40/64\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.7534 - accuracy: 0.5781 - val_loss: 0.7569 - val_accuracy: 0.7222\n",
            "Epoch 41/64\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.7697 - accuracy: 0.6719 - val_loss: 0.8642 - val_accuracy: 0.5764\n",
            "Epoch 42/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.5086 - accuracy: 0.8103 - val_loss: 0.9758 - val_accuracy: 0.5694\n",
            "Epoch 43/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 0.6248 - accuracy: 0.7188 - val_loss: 0.7658 - val_accuracy: 0.5764\n",
            "Epoch 44/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.5344 - accuracy: 0.7812 - val_loss: 0.6972 - val_accuracy: 0.5972\n",
            "Epoch 45/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.5121 - accuracy: 0.8125 - val_loss: 0.7919 - val_accuracy: 0.6042\n",
            "Epoch 46/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.4780 - accuracy: 0.8125 - val_loss: 1.0501 - val_accuracy: 0.6042\n",
            "Epoch 47/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.5516 - accuracy: 0.8281 - val_loss: 0.7727 - val_accuracy: 0.6736\n",
            "Epoch 48/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.5692 - accuracy: 0.7656 - val_loss: 0.7008 - val_accuracy: 0.6528\n",
            "Epoch 49/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.4945 - accuracy: 0.7812 - val_loss: 1.0264 - val_accuracy: 0.5486\n",
            "Epoch 50/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6309 - accuracy: 0.7344 - val_loss: 0.6323 - val_accuracy: 0.6875\n",
            "Epoch 51/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.4494 - accuracy: 0.8281 - val_loss: 0.7251 - val_accuracy: 0.6806\n",
            "Epoch 52/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.4712 - accuracy: 0.7656 - val_loss: 1.1071 - val_accuracy: 0.5556\n",
            "Epoch 53/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.5720 - accuracy: 0.7812 - val_loss: 0.8346 - val_accuracy: 0.7083\n",
            "Epoch 54/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.7070 - accuracy: 0.7414 - val_loss: 0.9847 - val_accuracy: 0.5903\n",
            "Epoch 55/64\n",
            "8/8 [==============================] - 26s 4s/step - loss: 0.5234 - accuracy: 0.7344 - val_loss: 0.6989 - val_accuracy: 0.6528\n",
            "Epoch 56/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.4629 - accuracy: 0.7969 - val_loss: 0.7030 - val_accuracy: 0.6528\n",
            "Epoch 57/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.4599 - accuracy: 0.8125 - val_loss: 0.9005 - val_accuracy: 0.5903\n",
            "Epoch 58/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 0.6705 - accuracy: 0.7188 - val_loss: 0.6201 - val_accuracy: 0.6875\n",
            "Epoch 59/64\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.6888 - accuracy: 0.7069 - val_loss: 1.1695 - val_accuracy: 0.5833\n",
            "Epoch 60/64\n",
            "8/8 [==============================] - 27s 4s/step - loss: 0.6254 - accuracy: 0.7656 - val_loss: 0.9381 - val_accuracy: 0.5764\n",
            "Epoch 61/64\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.6883 - accuracy: 0.7969 - val_loss: 0.7215 - val_accuracy: 0.6806\n",
            "Epoch 62/64\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.6806 - accuracy: 0.7031 - val_loss: 1.0189 - val_accuracy: 0.5764\n",
            "Epoch 63/64\n",
            "8/8 [==============================] - 26s 4s/step - loss: 0.5763 - accuracy: 0.8125 - val_loss: 0.7924 - val_accuracy: 0.6111\n",
            "Epoch 64/64\n",
            "8/8 [==============================] - 25s 4s/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.6335 - val_accuracy: 0.7014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e84f76260>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "\n",
        "model.fit(x=train_data,steps_per_epoch=8, epochs = 64, validation_data=test_data, validation_steps=test_data.samples//batch_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}